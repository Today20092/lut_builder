# src/lut_builder/engine.py

import colour
import numpy as np
from datetime import datetime
from pathlib import Path
from .data import (
    CAMERA_PROFILES,
    TARGET_PROFILES,
    MIDDLE_GREY,
    LUMA_WEIGHTS,
    hex_to_rgb,
)


def build_header(
    profile_name: str,
    target_name: str,
    cube_size: int,
    bands: list[dict],
    black_clip: bool,
    black_hex: str,
    white_clip: bool,
    white_hex: str,
) -> str:
    """
    Build a comment block for the top of the .cube file.
    Lines starting with # are ignored by all LUT processors.
    """
    profile = CAMERA_PROFILES[profile_name]
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    lines = [
        "#",
        "# ╔══════════════════════════════════════════════════════════╗",
        "# ║               LUT Builder — Custom Exposure LUT          ║",
        "# ╚══════════════════════════════════════════════════════════╝",
        "#",
        f"# Generated   : {now}",
        f"# Source       : {profile_name}",
        f"#   Gamut      : {profile['gamut']}",
        f"#   Log        : {profile['log']}",
        f"#   White clip : +{profile['white_clip_stops']} stops above middle grey",
        f"#   Black clip : {profile['black_clip_stops']} stops below middle grey",
        f"# Target       : {target_name}",
        f"# Cube size    : {cube_size}x{cube_size}x{cube_size}",
        "#",
        "# Middle Grey  : 0.18 scene-linear (universal photographic constant)",
        "# Luminance    : ITU-R BT.709 weights [R:0.2126, G:0.7152, B:0.0722]",
        "#",
    ]

    # False color bands
    if bands:
        lines.append("# False Color Bands:")
        for band in bands:
            label = (
                f"+{band['stop']:.1f}" if band["stop"] >= 0 else f"{band['stop']:.1f}"
            )
            lines.append(
                f"#   Stop {label:>5}  ±{band['width']:.2f} stops  →  {band['color']}"
            )
    else:
        lines.append("# False Color Bands : none")

    lines.append("#")

    # Clipping indicators
    lines.append("# Clipping Indicators:")
    if white_clip:
        lines.append(f"#   Clipped highlights →  {white_hex}")
    else:
        lines.append("#   Clipped highlights →  disabled")
    if black_clip:
        lines.append(f"#   Crushed shadows    →  {black_hex}")
    else:
        lines.append("#   Crushed shadows    →  disabled")

    lines.append("#")
    lines.append("# Generated by github.com/YOUR_USERNAME/lut-builder")
    lines.append("#")
    lines.append("")  # blank line before LUT data

    return "\n".join(lines)


def generate_lut(
    profile_name: str,
    target_name: str,
    cube_size: int,
    bands: list[dict],
    black_clip: bool,
    black_hex: str,
    white_clip: bool,
    white_hex: str,
    output_filename: str,
):
    profile = CAMERA_PROFILES[profile_name]
    target = TARGET_PROFILES[target_name]

    # 1. Initialize LUT
    lut = colour.LUT3D(size=cube_size)
    lut.name = f"{profile_name} to {target_name} Custom Assist"
    samples = lut.table.reshape(-1, 3)

    # 2. Get colour spaces
    src_gs = colour.RGB_COLOURSPACES[profile["gamut"]]
    tgt_gs = colour.RGB_COLOURSPACES[target["gamut"]]

    # 3. Log to Linear
    # colour-science handles the curve math entirely. The library guarantees
    # that whatever the camera's log encoding maps to middle grey will decode
    # to exactly MIDDLE_GREY (0.18) in scene-linear space — no per-camera
    # config is needed for this.
    linear_data = colour.models.log_decoding(samples, method=profile["log"])

    # 4. Compute perceptual luminance in linear space
    # We use ITU-R BT.709 luminance weights (defined in data.py as LUMA_WEIGHTS)
    # rather than a simple mean of R, G, B channels. A plain mean treats all
    # three channels as equally bright, which does not match human vision.
    # Proper weighting ensures the false-color and clipping masks respond to
    # how bright a pixel actually looks, not just its mathematical average.
    #
    # One stop of exposure = doubling of linear light.
    # Stops relative to middle grey: log2(luma / MIDDLE_GREY)
    #   +1 stop → luma = 0.36  → log2(0.36 / 0.18) =  1.0
    #   -1 stop → luma = 0.09  → log2(0.09 / 0.18) = -1.0
    luma = np.dot(linear_data, LUMA_WEIGHTS)
    stops = np.log2(np.maximum(luma, 1e-6) / MIDDLE_GREY)

    # 5. Gamut conversion (wide gamut → target gamut, done in linear light)
    rgb_linear_tgt = colour.RGB_to_RGB(linear_data, src_gs, tgt_gs)

    # 6. Apply output transfer function
    # Display targets like Rec.709 and Rec.2020 use an OETF (Opto-Electronic
    # Transfer Function), not a log encoding. The "encoding" field in the
    # target profile tells us which path to take.
    if target["encoding"] == "oetf":
        final_data = colour.models.oetf(rgb_linear_tgt, function=target["gamma"])
    else:
        final_data = colour.models.log_encoding(rgb_linear_tgt, method=target["gamma"])

    # 7. Apply false color bands (applied in order — last band wins on overlap)
    for band in bands:
        band_rgb = hex_to_rgb(band["color"])
        half = band["width"]
        mask = (stops >= (band["stop"] - half)) & (stops <= (band["stop"] + half))
        final_data[mask] = band_rgb

    # 8. Apply black clipping highlight
    # Uses the camera's known noise floor from the profile.
    # The colour library decodes the log curve correctly but has no knowledge
    # of where the sensor physically clips — that is a hardware property unique
    # to each camera and must come from the profile.
    if black_clip and black_hex:
        black_rgb = hex_to_rgb(black_hex)
        black_mask = stops <= profile["black_clip_stops"]
        final_data[black_mask] = black_rgb

    # 9. Apply white clipping highlight
    # Same reasoning as above — physical sensor ceiling, not a math limit.
    if white_clip and white_hex:
        white_rgb = hex_to_rgb(white_hex)
        white_mask = stops >= profile["white_clip_stops"]
        final_data[white_mask] = white_rgb

    # 10. Format and write LUT data
    lut.table = (
        np.clip(final_data, 0, 1)
        .reshape(cube_size, cube_size, cube_size, 3)
        .astype(np.float32)
    )

    output_path = Path(output_filename)
    colour.write_LUT(lut, str(output_path))

    # 11. Prepend comment header to the .cube file
    # The .cube format allows any number of # comment lines before the data.
    # All major LUT processors (DaVinci Resolve, Premiere, on-set monitors)
    # skip these lines cleanly.
    header = build_header(
        profile_name=profile_name,
        target_name=target_name,
        cube_size=cube_size,
        bands=bands,
        black_clip=black_clip,
        black_hex=black_hex,
        white_clip=white_clip,
        white_hex=white_hex,
    )
    original = output_path.read_text()
    output_path.write_text(header + original)

    return output_path
